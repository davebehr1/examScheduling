{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting appnope==0.1.0\n",
      "  Downloading appnope-0.1.0-py2.py3-none-any.whl (4.0 kB)\n",
      "Requirement already satisfied: bleach==3.1.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.1.5)\n",
      "Collecting certifi==2016.9.26\n",
      "  Downloading certifi-2016.9.26-py2.py3-none-any.whl (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator==4.4.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (4.4.2)\n",
      "Requirement already satisfied: defusedxml==0.6.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.6.0)\n",
      "Collecting entrypoints==0.2.3\n",
      "  Downloading entrypoints-0.2.3-py2.py3-none-any.whl (9.4 kB)\n",
      "Collecting ipykernel==4.10.0\n",
      "  Downloading ipykernel-4.10.0-py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 14.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipynb-py-convert==0.4.6\n",
      "  Downloading ipynb-py-convert-0.4.6.tar.gz (3.9 kB)\n",
      "Collecting ipython==5.8.0\n",
      "  Downloading ipython-5.8.0-py3-none-any.whl (758 kB)\n",
      "\u001b[K     |████████████████████████████████| 758 kB 16.0 MB/s eta 0:00:01     |███████████████████████         | 542 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
      "Collecting ipython-sql==0.4.0\n",
      "  Downloading ipython_sql-0.4.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: Jinja2==2.11.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (2.11.2)\n",
      "Collecting jsonschema==2.6.0\n",
      "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting jupyter-client==5.3.3\n",
      "  Downloading jupyter_client-5.3.3-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 2.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-core==4.5.0\n",
      "  Downloading jupyter_core-4.5.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 7.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting mistune==0.8.3\n",
      "  Downloading mistune-0.8.3-py2.py3-none-any.whl (16 kB)\n",
      "Collecting nbconvert==5.5.0\n",
      "  Downloading nbconvert-5.5.0-py2.py3-none-any.whl (447 kB)\n",
      "\u001b[K     |████████████████████████████████| 447 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbformat==5.0.7 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (5.0.7)\n",
      "Collecting notebook==5.6.0\n",
      "  Downloading notebook-5.6.0-py2.py3-none-any.whl (8.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.9 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging==20.4 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 20)) (20.4)\n",
      "Requirement already satisfied: pandocfilters==1.4.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 21)) (1.4.2)\n",
      "Collecting pexpect==4.6.0\n",
      "  Downloading pexpect-4.6.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pickleshare==0.7.4\n",
      "  Downloading pickleshare-0.7.4-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting prettytable==0.7.2\n",
      "  Downloading prettytable-0.7.2.tar.bz2 (21 kB)\n",
      "Requirement already satisfied: prometheus-client==0.8.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 25)) (0.8.0)\n",
      "Collecting prompt-toolkit==1.0.15\n",
      "  Downloading prompt_toolkit-1.0.15-py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psycopg2-binary==2.8.5\n",
      "  Downloading psycopg2_binary-2.8.5-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 917 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ptyprocess==0.6.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 28)) (0.6.0)\n",
      "Requirement already satisfied: Pygments==2.6.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 29)) (2.6.1)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 30)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 31)) (2.8.1)\n",
      "Collecting pytz==2020.1\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Send2Trash==1.5.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 33)) (1.5.0)\n",
      "Collecting simplegeneric==0.8.1\n",
      "  Downloading simplegeneric-0.8.1.zip (12 kB)\n",
      "Requirement already satisfied: six==1.15.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 35)) (1.15.0)\n",
      "Requirement already satisfied: SQLAlchemy==1.3.19 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (1.3.19)\n",
      "Collecting sqlparse==0.3.1\n",
      "  Downloading sqlparse-0.3.1-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: testpath==0.4.4 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 38)) (0.4.4)\n",
      "Collecting tornado==5.1.1\n",
      "  Downloading tornado-5.1.1.tar.gz (516 kB)\n",
      "\u001b[K     |████████████████████████████████| 516 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm==4.48.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 40)) (4.48.2)\n",
      "Collecting traitlets==4.3.2\n",
      "  Downloading traitlets-4.3.2-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wcwidth==0.2.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 42)) (0.2.5)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 43)) (0.5.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython==5.8.0->-r requirements.txt (line 9)) (49.6.0.post20200814)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from Jinja2==2.11.2->-r requirements.txt (line 12)) (1.1.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client==5.3.3->-r requirements.txt (line 14)) (19.0.2)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from notebook==5.6.0->-r requirements.txt (line 19)) (0.8.3)\n",
      "Building wheels for collected packages: ipynb-py-convert, prettytable, simplegeneric, tornado\n",
      "  Building wheel for ipynb-py-convert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipynb-py-convert: filename=ipynb_py_convert-0.4.6-py3-none-any.whl size=4625 sha256=9d4531b2d9d931ea2fe279ef6ac1d353e8604f61af1f4fc669d1dcee7fa59315\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/49/ee/0a/ff1f946e7969e39aec10a28d84692859084219f27d2ae35119\n",
      "  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13700 sha256=7b9fb62b2c86adef1371278ae26ac32636108718e0945b19b1e7208ec64df1a4\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/46/60/6c/bb25d05df22906786206e901e9354bb3061061191116768bee\n",
      "  Building wheel for simplegeneric (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for simplegeneric: filename=simplegeneric-0.8.1-py3-none-any.whl size=5074 sha256=34d873d7ae957a90f08d70a7ba3d3f284a2dff3ff0dbdbd473bedf4d8b69cb90\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/0b/32/6b/5f5447909a062da20dfe432fa945d8f98636692637deccaa8a\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tornado: filename=tornado-5.1.1-cp38-cp38-linux_x86_64.whl size=462748 sha256=b23d9611ee95d3cb3dfb3d2f6ccd2bcd7afea61c823b06c941cec82066de548e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/25/a1/e3/b0d37c6c451fc21f290cf026f6352382e6cbced32dc3f6a37a\n",
      "Successfully built ipynb-py-convert prettytable simplegeneric tornado\n",
      "Installing collected packages: appnope, certifi, entrypoints, tornado, pickleshare, traitlets, simplegeneric, pexpect, prompt-toolkit, ipython, jupyter-core, jupyter-client, ipykernel, ipynb-py-convert, sqlparse, prettytable, ipython-sql, jsonschema, mistune, nbconvert, notebook, psycopg2-binary, pytz\n",
      "  Attempting uninstall: certifi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found existing installation: certifi 2020.6.20\n",
      "    Uninstalling certifi-2020.6.20:\n",
      "      Successfully uninstalled certifi-2020.6.20\n",
      "  Attempting uninstall: entrypoints\n",
      "    Found existing installation: entrypoints 0.3\n",
      "    Uninstalling entrypoints-0.3:\n",
      "      Successfully uninstalled entrypoints-0.3\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.0.4\n",
      "    Uninstalling tornado-6.0.4:\n",
      "      Successfully uninstalled tornado-6.0.4\n",
      "  Attempting uninstall: pickleshare\n",
      "    Found existing installation: pickleshare 0.7.5\n",
      "    Uninstalling pickleshare-0.7.5:\n",
      "      Successfully uninstalled pickleshare-0.7.5\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 4.3.3\n",
      "    Uninstalling traitlets-4.3.3:\n",
      "      Successfully uninstalled traitlets-4.3.3\n",
      "  Attempting uninstall: pexpect\n",
      "    Found existing installation: pexpect 4.8.0\n",
      "    Uninstalling pexpect-4.8.0:\n",
      "      Successfully uninstalled pexpect-4.8.0\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.6\n",
      "    Uninstalling prompt-toolkit-3.0.6:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.6\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.17.0\n",
      "    Uninstalling ipython-7.17.0:\n",
      "      Successfully uninstalled ipython-7.17.0\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.6.3\n",
      "    Uninstalling jupyter-core-4.6.3:\n",
      "      Successfully uninstalled jupyter-core-4.6.3\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 6.1.6\n",
      "    Uninstalling jupyter-client-6.1.6:\n",
      "      Successfully uninstalled jupyter-client-6.1.6\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 5.3.4\n",
      "    Uninstalling ipykernel-5.3.4:\n",
      "      Successfully uninstalled ipykernel-5.3.4\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 3.2.0\n",
      "    Uninstalling jsonschema-3.2.0:\n",
      "      Successfully uninstalled jsonschema-3.2.0\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 5.6.1\n",
      "    Uninstalling nbconvert-5.6.1:\n",
      "      Successfully uninstalled nbconvert-5.6.1\n",
      "  Attempting uninstall: notebook\n",
      "    Found existing installation: notebook 6.1.3\n",
      "    Uninstalling notebook-6.1.3:\n",
      "      Successfully uninstalled notebook-6.1.3\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "requests 2.24.0 requires certifi>=2017.4.17, but you'll have certifi 2016.9.26 which is incompatible.\n",
      "jupyterlab-server 1.2.0 requires jsonschema>=3.0.1, but you'll have jsonschema 2.6.0 which is incompatible.\u001b[0m\n",
      "Successfully installed appnope-0.1.0 certifi-2016.9.26 entrypoints-0.2.3 ipykernel-4.10.0 ipynb-py-convert-0.4.6 ipython-5.8.0 ipython-sql-0.4.0 jsonschema-2.6.0 jupyter-client-5.3.3 jupyter-core-4.5.0 mistune-0.8.3 nbconvert-5.5.0 notebook-5.6.0 pexpect-4.6.0 pickleshare-0.7.4 prettytable-0.7.2 prompt-toolkit-1.0.15 psycopg2-binary-2.8.5 pytz-2020.1 simplegeneric-0.8.1 sqlparse-0.3.1 tornado-5.1.1 traitlets-4.3.2\n",
      "Requirement already satisfied: MarkupSafe in /opt/conda/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.8/site-packages (2.8.5)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.1-cp38-cp38-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 1.2 MB/s eta 0:00:01    |█████▍                          | 1.8 MB 4.3 MB/s eta 0:00:03     |████████▍                       | 2.7 MB 1.3 MB/s eta 0:00:07     |█████████████████▋              | 5.7 MB 1.1 MB/s eta 0:00:05     |█████████████████▊              | 5.7 MB 1.1 MB/s eta 0:00:05     |█████████████████████▏          | 6.9 MB 291 kB/s eta 0:00:13\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Collecting numpy>=1.15.4\n",
      "  Downloading numpy-1.19.1-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 338 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.19.1 pandas-1.1.1\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (1.19.1)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/lib/python3.8/site-packages (19.0.2)\n",
      "Requirement already satisfied: terminado in /opt/conda/lib/python3.8/site-packages (0.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "! pip install MarkupSafe\n",
    "! pip install psycopg2-binary\n",
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install pyzmq\n",
    "! pip install terminado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "from sqlalchemy import Column, Integer, Text, ForeignKey,String,Table, DateTime\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from datetime import datetime\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"test.exam\"\n",
    "sample_one_early =\"./itc2007_dataset/exam_comp_set4.exam\" #done\n",
    "sample_two_early =\"./itc2007_dataset/exam_comp_set1.exam\"\n",
    "\n",
    "sample_one_late = \"./itc2007_dataset/exam_comp_set6.exam\"#done\n",
    "sample_two_late = \"./itc2007_dataset/exam_comp_set8.exam\"#done\n",
    "\n",
    "\n",
    "sample_one_hidden = \"./itc2007_dataset/exam_comp_set9.exam\" #done\n",
    "sample_two_hidden = \"./itc2007_dataset/exam_comp_set12.exam\" #done\n",
    "\n",
    "sample = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine('postgresql://postgres:password@postgres:5432/postgres')\n",
    "connection = engine.connect()\n",
    "meta = db.MetaData(connection)\n",
    "Base = declarative_base()\n",
    "Session = sessionmaker(bind = engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_table = Table('exam_student', Base.metadata,\n",
    "    Column('id',db.Integer, primary_key=True),\n",
    "    Column('exam_id', Integer, ForeignKey('exam.id',ondelete=\"cascade\")),\n",
    "    Column('student_id', Integer, ForeignKey('student.id',ondelete=\"cascade\"))\n",
    ")\n",
    "\n",
    "association_two = Table('exam_period', Base.metadata,\n",
    "    Column('id',db.Integer, primary_key=True),\n",
    "    Column('exam_id', Integer, ForeignKey('exam.id',ondelete=\"cascade\")),\n",
    "    Column('period_id', Integer, ForeignKey('period.id',ondelete=\"cascade\"))\n",
    ")\n",
    "\n",
    "association_three = Table('exam_room', Base.metadata,\n",
    "    Column('id',db.Integer, primary_key=True),\n",
    "    Column('exam_id', Integer, ForeignKey('exam.id',ondelete=\"cascade\")),\n",
    "    Column('room_id', Integer, ForeignKey('room.id',ondelete=\"cascade\"))\n",
    ")\n",
    "\n",
    "class Exam(Base):\n",
    "    __tablename__ = 'exam'\n",
    "\n",
    "    id = Column(Integer, primary_key = True)\n",
    "    duration = Column(Integer)\n",
    "    students = relationship(\n",
    "    \"Student\",\n",
    "    secondary=association_table,\n",
    "    back_populates=\"exams\",\n",
    "    cascade=\"all, delete\", passive_deletes=True)\n",
    "    periods = relationship(\n",
    "    \"Period\",\n",
    "    secondary=association_two,\n",
    "    back_populates=\"exams\",\n",
    "    cascade=\"all, delete\", passive_deletes=True)\n",
    "    rooms = relationship(\n",
    "    \"Room\",\n",
    "    secondary=association_three,\n",
    "    back_populates=\"exams\",\n",
    "    cascade=\"all, delete\", passive_deletes=True)\n",
    "\n",
    "\n",
    "    \n",
    "class Student(Base):\n",
    "    __tablename__ = 'student'\n",
    "\n",
    "    id = Column(Integer, primary_key = True)\n",
    "    #    examid = Column(Integer, ForeignKey('exams.id'))\n",
    "    number = Column(Integer)\n",
    "    #    exams = relationship(Exam,secondary='link')\n",
    "    exams = relationship(\n",
    "        \"Exam\",\n",
    "        secondary=association_table,\n",
    "        back_populates=\"students\",\n",
    "        cascade=\"all, delete\", passive_deletes=True)\n",
    "\n",
    "\n",
    "class Room(Base):\n",
    "   __tablename__ = 'room'\n",
    "   \n",
    "   id = Column(Integer, primary_key = True)\n",
    "   capacity = Column(Integer)\n",
    "   penalty = Column(Integer)\n",
    "   exams = relationship(\n",
    "        \"Exam\",\n",
    "        secondary=association_three,\n",
    "        back_populates=\"rooms\",\n",
    "        cascade=\"all, delete\", passive_deletes=True)\n",
    "\n",
    "\n",
    "class Period(Base):\n",
    "    __tablename__ = 'period'\n",
    "    id = Column(Integer, primary_key = True)\n",
    "    time = Column(DateTime)\n",
    "    duration = Column(Integer)\n",
    "    penalty = Column(Integer)\n",
    "    exams = relationship(\n",
    "        \"Exam\",\n",
    "        secondary=association_two,\n",
    "        back_populates=\"periods\",\n",
    "        cascade=\"all, delete\", passive_deletes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exam_student\n",
      "exam_room\n",
      "exam_period\n",
      "student\n",
      "room\n",
      "period\n",
      "exam\n"
     ]
    }
   ],
   "source": [
    "for tbl in reversed(Base.metadata.sorted_tables):\n",
    "    print(tbl.name)\n",
    "    truncate_table = db.text(\"TRUNCATE TABLE \" + tbl.name + \" RESTART IDENTITY CASCADE\")\n",
    "    engine.execute(truncate_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constraint:\n",
    "    def __init__(self,ctype,name,periods):\n",
    "        self.ctype = ctype\n",
    "        self.name = name\n",
    "        self.periods = periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftConstraint:\n",
    "    def __init__(self,name,params):\n",
    "        self.name = name\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomRows = []\n",
    "\n",
    "with open(sample) as f:\n",
    "     for line in f:\n",
    "        if \"Exams\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"Exams\"\n",
    "        if \"Periods\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"Periods\"\n",
    "        if \"Rooms\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"Rooms\"\n",
    "        if \"PeriodHardConstraints\" in line:\n",
    "            lineType = \"PeriodHardConstraints\"\n",
    "            line = f.readline()\n",
    "        if \"RoomHardConstraints\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"RoomHardConstraints\"\n",
    "        if \"InstitutionalWeightings\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"InstitutionalWeightings\"\n",
    "            \n",
    "        if(lineType == 'Rooms'):\n",
    "            arr = line.split(',')\n",
    "            r1 = Room(capacity = arr[0],penalty = arr[1])\n",
    "            roomRows.append(r1)\n",
    "        \n",
    "session.add_all(roomRows)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period ['2', ' EXAM_COINCIDENCE', ' 3\\n']\n",
      "period ['1', ' EXCLUSION', ' 5\\n']\n",
      "period ['0', ' AFTER', ' 9\\n']\n",
      "room ['9', ' ROOM_EXCLUSIVE\\n']\n",
      "['TWOINAROW', '7']\n",
      "['TWOINADAY', '5']\n",
      "['PERIODSPREAD', '2', '20']\n",
      "['PERIODSPREAD', '5', '2']\n",
      "['NOMIXEDDURATIONS', '10']\n",
      "['FRONTLOAD', '1', '5', '10']\n"
     ]
    }
   ],
   "source": [
    "examRows =[]\n",
    "periodRows = []\n",
    "studentRows = []\n",
    "# roomRows = []\n",
    "students = []\n",
    "constraints = []\n",
    "softconstraints =[]\n",
    "examcount = 0\n",
    "periodcount = 0\n",
    "roomcount = 0\n",
    "lineType = \"\"\n",
    "with open(sample) as f:\n",
    "     for line in f:\n",
    "        if \"Exams\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"Exams\"\n",
    "        if \"Periods\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"Periods\"\n",
    "        if \"Rooms\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"Rooms\"\n",
    "        if \"PeriodHardConstraints\" in line:\n",
    "            lineType = \"PeriodHardConstraints\"\n",
    "            line = f.readline()\n",
    "        if \"RoomHardConstraints\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"RoomHardConstraints\"\n",
    "        if \"InstitutionalWeightings\" in line:\n",
    "            line = f.readline()\n",
    "            lineType = \"InstitutionalWeightings\"\n",
    "        \n",
    "        \n",
    "        if(lineType == 'Periods'):\n",
    "            arr = line.split(',')\n",
    "            dateTime = arr[0] + arr[1]\n",
    "            p1 = Period(time = datetime.strptime(dateTime,'%d:%m:%Y %H:%M:%S'),duration = arr[2],penalty = arr[3])\n",
    "            periodRows.append(p1)\n",
    "        \n",
    "        if(lineType == 'PeriodHardConstraints'):\n",
    "            arr = line.split(',')\n",
    "            print(\"period\",arr)\n",
    "            c1 = Constraint(\"period\",name =arr[1].strip(),periods = [int(arr[0].strip()) + 1, int(arr[2].strip()) + 1])\n",
    "            constraints.append(c1)\n",
    "\n",
    "        if(lineType == 'RoomHardConstraints'):\n",
    "            arr = line.split(',')\n",
    "            print(\"room\",arr)\n",
    "            if len(arr) > 1 :\n",
    "                c1 = Constraint(\"room\",name = arr[1].strip(),periods = [int(arr[0].strip())+1])\n",
    "                constraints.append(c1)\n",
    "            else:\n",
    "                c1 = Constraint(\"room\",name = arr[0].strip(),periods = None)\n",
    "                constraints.append(c1)\n",
    "        if(lineType == \"InstitutionalWeightings\"):\n",
    "            arr = [x.strip() for x in line.split(',')]\n",
    "            print(arr)\n",
    "            sc1 = SoftConstraint(name = arr[0],params = [int(i) for i in arr[1:]])\n",
    "            softconstraints.append(sc1)\n",
    "                 \n",
    "        if(lineType == 'Exams'):\n",
    "            arr = line.split(',')\n",
    "            examRows.append(Exam(duration = int(arr[0])))\n",
    "            examRows[examcount].rooms.append(roomRows[random.randint(0,len(roomRows)-1)])\n",
    "        \n",
    "            for no in arr[1:]:\n",
    "                no = no.strip()\n",
    "                no = int(no)\n",
    "                if no not in students:\n",
    "                    students.append(int(no))\n",
    "                    tempStudent = Student(number = int(no))\n",
    "                    studentRows.append(tempStudent)\n",
    "                if no in students:\n",
    "                    studentRows[students.index(no)].exams.append(examRows[examcount])\n",
    "#                     examRows[examcount].students.append(studentRows[students.index(no)])\n",
    "            examcount += 1\n",
    "        \n",
    "session.add_all(examRows)\n",
    "session.add_all(periodRows)\n",
    "session.add_all(studentRows)\n",
    "session.add_all(roomRows)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWOINAROW\n",
      "[7]\n",
      "TWOINADAY\n",
      "[5]\n",
      "PERIODSPREAD\n",
      "[2, 20]\n",
      "PERIODSPREAD\n",
      "[5, 2]\n",
      "NOMIXEDDURATIONS\n",
      "[10]\n",
      "FRONTLOAD\n",
      "[1, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "for cons in softconstraints:\n",
    "    print(cons.name)\n",
    "    print(cons.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateStatisHeurisitcs():\n",
    "    sql_query = db.text(\"create or replace view staticHeuristics as  select a.exam_id, b.student_id, b.exam_count, a.student_count from ( select exam_id, count(student_id) as student_count from exam_student group by exam_id) as a, ( select student_id , count(exam_id) as exam_count from exam_student group by student_id) as b order by b.exam_count desc\")\n",
    "    connection.execute(sql_query)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateStatisHeurisitcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodHeuristics(allocated_periods,period_heuristic):\n",
    "    periods = ','.join([str(elem) for elem in allocated_periods]) \n",
    "    if(period_heuristic == 1):\n",
    "        sql_query = db.text(\"select id from period order by penalty limit 1\")\n",
    "        period = connection.execute(sql_query).fetchone()[0]\n",
    "        allocated_periods.append(period)\n",
    "    if(period_heuristic == 2):\n",
    "        sql_query = db.text(\"select id from period order by time asc limit 1\")\n",
    "        period = connection.execute(sql_query).fetchone()[0]\n",
    "        allocated_periods.append(period)\n",
    "    if(period_heuristic == 3):\n",
    "        sql_query = db.text(\"select id from period order by duration asc limit 1\")\n",
    "        period = connection.execute(sql_query).fetchone()[0]\n",
    "        allocated_periods.append(period)     \n",
    "    if(period_heuristic == 4):\n",
    "        sql_query = db.text(\"select id from period order by random() asc limit 1\")\n",
    "        period = connection.execute(sql_query).fetchone()[0]\n",
    "        allocated_periods.append(period)\n",
    "    return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(examRows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examHeuristics(allocated_exams,allocated_periods,exam_heuristic, period_heuristic, examH,periodH):\n",
    "    allocated = ','.join([str(elem) for elem in allocated_exams])\n",
    "    periodId = periodHeuristics(allocated_periods,period_heuristic)\n",
    "    if(exam_heuristic == 1 and examH != 1):\n",
    "        #schedule exam with most clashes first\n",
    "        sql_query = db.text(\"select exam_id from staticHeuristics  where exam_id not in (\" + allocated + \") order by exam_count desc limit 1\")\n",
    "        exam = connection.execute(sql_query).fetchone()\n",
    "        if exam is None:\n",
    "            return None\n",
    "        exam = exam[0]\n",
    "        examRows[exam-1].periods.append(periodRows[periodId -1])\n",
    "        session.add(examRows[exam-1])\n",
    "        session.commit()\n",
    "        allocated_exams.append(exam)\n",
    "    if(exam_heuristic == 2 and examH != 2):\n",
    "        #schedule exam with most students first\n",
    "        sql_query = db.text(\"select exam_id from staticheuristics where exam_id not in (\" + allocated + \")  order by student_count desc limit 1\")\n",
    "        exam = connection.execute(sql_query).fetchone()\n",
    "        if exam is None:\n",
    "            return None\n",
    "        exam = exam[0]\n",
    "        examRows[exam-1].periods.append(periodRows[periodId -1])\n",
    "        session.add(examRows[exam-1])\n",
    "        session.commit()\n",
    "        allocated_exams.append(exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristics(examH,periodH):\n",
    "    allocated_exams = [0]\n",
    "    allocated_periods = [0]\n",
    "    exam_heuristic = random.randint(1,2);\n",
    "    period_heuristic = random.randint(1,4);\n",
    "    while len(allocated_exams)-1 < len(examRows):\n",
    "        examHeuristics(allocated_periods,allocated_exams, exam_heuristic,period_heuristic,examH,periodH)\n",
    "        \n",
    "    return exam_heuristic,period_heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearPeriodTable():\n",
    "    for exam in examRows:\n",
    "        exam.periods.clear()\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations =[]\n",
    "def EvaluateSolution(sql_view):\n",
    "    dates = []\n",
    "    violationCount = 0\n",
    "    for constraint in constraints:\n",
    "        #2, EXAM_COINCIDENCE, 3\n",
    "        #exam 2 and 3 should be in the same period:\n",
    "        if(constraint.name == \"EXAM_COINCIDENCE\"):\n",
    "            sql_query = db.text(\"SELECT COUNT(DISTINCT period_id) FROM \" + sql_view + \" WHERE exam_id=:idOne OR exam_id =:idTwo\")\n",
    "            result = connection.execute(sql_query, idOne = constraint.periods[0],idTwo = constraint.periods[1])\n",
    "            for r in result:\n",
    "#                 print(r[0])\n",
    "                if(r[0] > 1):\n",
    "                    violationCount += 1\n",
    "                    violations.append(constraint)\n",
    "        #1, EXCLUSION, 5\n",
    "        #exam 1 and 5 should not be in the same period:\n",
    "        if(constraint.name == \"EXCLUSION\"):\n",
    "            sql_query = db.text(\"SELECT COUNT(DISTINCT period_id) FROM \" + sql_view + \" WHERE exam_id=:idOne OR exam_id =:idTwo\")\n",
    "            result = connection.execute(sql_query, idOne = constraint.periods[0],idTwo = constraint.periods[1])\n",
    "            for r in result:\n",
    "#                 print(r[0])\n",
    "                if(r[0] < 2):\n",
    "                    violationCount += 1\n",
    "                    violations.append(constraint)\n",
    "        #0, AFTER, 9\n",
    "        # 0 should be timetabled after 9 \n",
    "        if(constraint.name == \"AFTER\"):\n",
    "            sql_query = db.text(\"SELECT exam_id, datetime FROM (SELECT exam_id, time as datetime FROM \" + sql_view + \" INNER JOIN period ON \" + sql_view + \".period_id = period.id) AS T WHERE exam_id =:idOne OR exam_id =:idTwo ORDER BY exam_id\")\n",
    "            result = connection.execute(sql_query, idOne = constraint.periods[0],idTwo = constraint.periods[1])\n",
    "            for r in result:\n",
    "                dates.append(r[\"datetime\"])\n",
    "            \n",
    "            if(dates[0] < dates[1]):\n",
    "                violationCount += 1;\n",
    "            result_as_list = result.fetchall()\n",
    "        #9, ROOM_EXCLUSIVE\n",
    "        # exam 9 should be the only exam scheduled in a room\n",
    "        if(constraint.name.strip() == \"ROOM_EXCLUSIVE\"):\n",
    "            sql_query = db.text(\"SELECT COUNT(DISTINCT exam_id) as exam_count FROM \" + sql_view + \" WHERE room_id = (SELECT room_id FROM \" + sql_view + \" WHERE exam_id =1 limit 1) and period_id = (SELECT period_id FROM \" + sql_view + \" WHERE exam_id =:examId limit 1)\")\n",
    "            result = connection.execute(sql_query, examId = constraint.periods[0])\n",
    "            for r in result:\n",
    "                if(r[\"exam_count\"] > 1):\n",
    "                    violationCount += 1\n",
    "                    violations.append(constraint)\n",
    "            \n",
    "    return violationCount;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentScore(sql_view):\n",
    "    runningScore = 0\n",
    "    for cons in softconstraints:\n",
    "        if(cons.name == \"TWOINAROW\"):\n",
    "            sql_query = db.text(\"select Count(student_id) as studentCount from ( select prev_exam, time, elapsed_time, exam_id from ( select time, elapsed_time, exam_id, lag(exam_id) over ( order by exam_id) prev_exam from ( select exam_id, time, time - lag(time) over ( order by time) elapsed_time from ( select exam_id, time from \" + sql_view + \" inner join period on \" + sql_view +\".period_id = period.id) T order by time asc) T ) T where elapsed_time between '60 MINUTES' and '90 MINUTES') as exams inner join exam_student on exams.exam_id = exam_student.exam_id and exam_student.exam_id = exams.prev_exam\")\n",
    "            studentCount = connection.execute(sql_query).fetchone()[0]\n",
    "            runningScore += int(studentCount) * cons.params[0]\n",
    "        if(cons.name == \"TWOINADAY\"):\n",
    "            sql_query = db.text(\"select Count(student_id) as studentCount from ( select prev_exam, time, elapsed_time, exam_id from ( select time, elapsed_time, exam_id, lag(exam_id) over ( order by exam_id) prev_exam from ( select exam_id, time, time - lag(time) over ( order by time) elapsed_time from ( select exam_id, time from \" + sql_view + \" inner join period on \" +  sql_view + \".period_id = period.id) T order by time asc) T ) T where elapsed_time between '1 DAYS' and '2 DAYS') as exams inner join exam_student on exams.exam_id = exam_student.exam_id and exam_student.exam_id = exams.prev_exam\")\n",
    "            studentCount = connection.execute(sql_query).first()[0]\n",
    "            runningScore += int(studentCount) * cons.params[0]\n",
    "        if(cons.name == \"NOMIXEDDURATIONS\"):\n",
    "            sql_query = db.text(\"select sum(durations) as totalMixed from (SELECT period_id, count(distinct duration) as durations FROM ( select period_id, exam_id, duration, room_id from ( select \" + sql_view + \".exam_id, \" + sql_view + \".room_id, period_id from \" + sql_view + \" inner join exam_room on \" +  sql_view + \".exam_id = exam_room.exam_id order by period_id) as examrooms inner join exam on examrooms.exam_id = exam.id) T GROUP BY period_id HAVING COUNT(DISTINCT duration) > 1) T\");\n",
    "            mixedCount = connection.execute(sql_query).fetchone()[0]\n",
    "            runningScore += int(mixedCount) * cons.params[0]\n",
    "        \n",
    "    return runningScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSolution(sql_view):\n",
    "    heuristics(None,None)\n",
    "    query_string = \"CREATE OR REPLACE VIEW \" + sql_view + \" AS SELECT exam_period.exam_id, period_id, exam_room.room_id FROM exam_room INNER JOIN exam_period ON exam_room.exam_id = exam_period.exam_id\"\n",
    "    view_query = db.text(query_string)\n",
    "    connection.execute(view_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSolution(examH,periodH):\n",
    "    exam = None\n",
    "    period = None\n",
    "    clearPeriodTable()\n",
    "    exam,period = heuristics(examH,periodH)\n",
    "    createSolution(\"tempSolution2\")\n",
    "    return exam,period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "createSolution(\"tempSolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentSoftConstraintScore = getCurrentScore(\"tempSolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getSolutionScore(sql_view):\n",
    "#     currentScore = EvaluateSolution(sql_view)\n",
    "    \n",
    "#     currentSoftConstraintScore = getCurrentScore(sql_view)\n",
    "#     return currentScore + currentSoftConstraintScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentScore: 20\n"
     ]
    }
   ],
   "source": [
    "hardConstraintViolations = EvaluateSolution(\"tempSolution\")\n",
    "currentScore = getCurrentScore(\"tempSolution\")\n",
    "print(\"currentScore:\",currentScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 0\n",
      "neighbour score: 20\n",
      "neighbour hard violation count: 2\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 1\n",
      "neighbour score: 20\n",
      "neighbour hard violation count: 1\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 2\n",
      "neighbour score: 20\n",
      "neighbour hard violation count: 2\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 3\n",
      "neighbour score: 20\n",
      "neighbour hard violation count: 3\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 4\n",
      "neighbour score: 20\n",
      "neighbour hard violation count: 2\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 5\n",
      "neighbour score: 60\n",
      "neighbour hard violation count: 2\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 6\n",
      "neighbour score: 20\n",
      "neighbour hard violation count: 2\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 7\n",
      "neighbour score: 60\n",
      "neighbour hard violation count: 1\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 8\n",
      "neighbour score: 20\n",
      "neighbour hard violation count: 2\n",
      "amount of hard constraint violations so far 2\n",
      "current score: 20\n",
      "iteartion: 9\n",
      "neighbour score: 40\n",
      "neighbour hard violation count: 2\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "scores = []\n",
    "examHeuristic = 0\n",
    "periodHeuristic = 0\n",
    "examH = None\n",
    "periodH = None\n",
    "while iteration < 10:\n",
    "    random.seed(random.randint(3, 9))\n",
    "    print('amount of hard constraint violations so far', hardConstraintViolations)\n",
    "    print('current score:',currentScore)\n",
    "    print(\"iteartion:\",iteration)\n",
    "#     if currentScore == 0: \n",
    "#         break\n",
    "\n",
    "    examHeuristic,periodHeuristic = generateSolution(examH, periodH) \n",
    "\n",
    "    hardViolationCount = EvaluateSolution(\"tempSolution2\")  \n",
    "    \n",
    "    score = getCurrentScore(\"tempSolution2\") \n",
    "    scores.append(score)\n",
    "    print(\"neighbour score:\",score)\n",
    "    print(\"neighbour hard violation count:\",hardViolationCount)\n",
    "    if hardViolationCount > 0:\n",
    "        examH = examHeuristic\n",
    "        periodH = periodHeuristic\n",
    "    if score < currentScore : \n",
    "        drop_view = db.text(\"DROP VIEW tempSolution\")\n",
    "        connection.execute(drop_view)\n",
    "        alter_view = db.text(\"ALTER VIEW tempSolution2 RENAME TO tempSolution\")\n",
    "        connection.execute(alter_view)\n",
    "        currentScore = score\n",
    "#     clear_output(wait=True)\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_arr = np.asarray(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for : test.exam\n",
      "Objective scores: [20, 20, 20, 20, 20, 60, 20, 60, 20, 40]\n",
      "mean: 30.0\n",
      "std: 16.1245154965971\n",
      "min: 20\n",
      "best exam heuristic: 1 best period heuristic: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"result for :\", sample)\n",
    "print(\"Objective scores:\",scores)\n",
    "print(\"mean:\",np.mean(scores_arr))\n",
    "print(\"std:\",np.std(scores_arr))\n",
    "print (\"min:\",np.min(scores_arr))\n",
    "print(\"best exam heuristic:\",examHeuristic, \"best period heuristic:\",periodHeuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
